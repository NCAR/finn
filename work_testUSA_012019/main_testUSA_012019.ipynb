{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FINN Preprocessor: Local application, Preloaded MODIS raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Envoronments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely no need to be edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import subprocess\n",
    "import shlex\n",
    "from urllib.parse import urlparse\n",
    "from importlib import reload\n",
    "import gdal\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# finn preproc codes\n",
    "sys.path = sys.path + ['../code_anaconda']\n",
    "import downloader\n",
    "import af_import\n",
    "import rst_import\n",
    "import polygon_import\n",
    "import run_step1\n",
    "import run_step2\n",
    "import export_shp\n",
    "import plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database settings\n",
    "os.environ['PGDATABASE'] = 'gis'\n",
    "os.environ['PGUSER'] = 'finn'\n",
    "os.environ['PGPASSWORD'] = 'finn'\n",
    "os.environ['PGHOST'] = 'localhost'\n",
    "os.environ['PGPORT'] = '5432'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the PostGIS database is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info for the database\n",
    "!psql postgres -c 'SELECT version();'\n",
    "!pg_lsclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO i want to move this to Dockerfile somehow\n",
    "# create plpython, needed only once for the database\n",
    "try:\n",
    "    p = subprocess.run(shlex.split(\"psql -d %s -c 'CREATE LANGUAGE plpython3u;'\" % os.environ['PGDATABASE']), \n",
    "                       check=True, stderr=subprocess.PIPE)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    if 'already exists' in e.stderr.decode():\n",
    "        print(e.stderr.decode().replace('ERROR','OK').strip())\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for ActiveFire Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You specify two items related active filre.\n",
    "1. `tag_af`: a string that identifies this active fire dataset through the processing.\n",
    "2. `af_fnames`: list of path for the shape files you downloaded from FIRMS website  \n",
    "Files you specified as `af_names` will be imported into a databse schema \"af_<i>tag_af</i>\", and processed in the database.  \n",
    "Final output file will be \"out_<i>tag_af</i>_*.csv\".\n",
    "3. `firstday`, `lastday`: (optional) you specify first/last year of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag to identify active fire dataset\n",
    "# USA (excl. ALK) 7 days fire downloaded 2019-01-13 \n",
    "tag_af = 'testUSA_012019'\n",
    "\n",
    "# shp file names\n",
    "af_fnames = [\n",
    "    '../downloads/firms/testUSA_012019/MODIS_C6_USA_contiguous_and_Hawaii_7d.shp',\n",
    "    '../downloads/firms/testUSA_012019/VNP14IMGTDL_NRT_USA_contiguous_and_Hawaii_7d.shp',\n",
    "]\n",
    "\n",
    "# You can either set fist and last day of analysis by your self here,\n",
    "# firstday = datetime.date(year, 1, 1)\n",
    "# lastday = datetime.date(year+1, 1, 1)\n",
    "\n",
    "# or use the period covered by the input active fire file (keep both variables to None)\n",
    "firstday = None\n",
    "lastday = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular sample AF dataset are provided by the developper.  In other applications, it will be user's resoponsibility to provide shape file for active fire in specified path/name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check input file exists\n",
    "if any([not os.path.exists(_) for _ in af_fnames]):\n",
    "    print(\"Not found:\\n\" + '\\n'.join(af_fnames) + '\\n\\n')\n",
    "    raise RuntimeError('AF inputs not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for Land Surface Datasets (land cover, vegetation continuous field, region definieons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIS land cover types, MODIS vegetation continuous field will be downloaded, if needed, for the region of AF input\n",
    "1. `year_rst`: MODIS raster data year to be used for the analysis\n",
    "\n",
    "Other parameters such as `tag_lct`, `tag_vcf`, `tag_regnum` (identify landcover, vcf and region number dataset) are set automatically for MODIS dataset.  \n",
    "The datasets are imported into database schema \"raster\", with table names \"rst_<i>tag_lct</i>\", or \"rst_modlct_2017\", for example.  \n",
    "An overview raster \"o_32_rst_modlct_2007\" is created as well, as the real dataset is difficult to handle for QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS raster datasets' year\n",
    "year_rst = 2017\n",
    "# or you can match it to years of active fire file\n",
    "#year_rst = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year_rst is None:\n",
    "    if any(_ is None for _ in (firstday, lastday)):\n",
    "        # read from shape file\n",
    "        raise RuntimeError(\"year_rst speficication from AF data has not implemented yet\")\n",
    "    else:\n",
    "        # assume first day of analysis is year of interest\n",
    "        year_rst = firstday.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag to identify datasets, automatically set to be modlct_YYYY, modvcf_YYYY\n",
    "tag_lct = 'modlct_%d' % year_rst\n",
    "tag_vcf = 'modvcf_%d' % year_rst\n",
    "\n",
    "# tag for the region number polygon\n",
    "tag_regnum = 'regnum'\n",
    "\n",
    "# definition of variables in the raster files\n",
    "rasters = [\n",
    "        {\n",
    "            'tag': tag_lct,\n",
    "            'kind': 'thematic',\n",
    "            'variable': 'lct'\n",
    "        },\n",
    "        {\n",
    "            'tag': tag_vcf,\n",
    "            'kind': 'continuous',\n",
    "            'variables': ['tree', 'herb', 'bare'],\n",
    "        },\n",
    "        {\n",
    "            'tag': tag_regnum,\n",
    "            'kind': 'polygons',\n",
    "            'variable_in': 'region_num',\n",
    "            'variable': 'regnum',\n",
    "        },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import active fire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and import into database.\n",
    "\n",
    "<b>Be careful!!</b> The code has no safe guard and wipe the schema for the scheama \"af_<i>tag_af</i>\" and starts over.  \n",
    "\n",
    "Let me think the design a bit more for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(af_import)\n",
    "\n",
    "# TODO this is destructive need to safe guard!\n",
    "# tell user schema is there, list table names and # of row of each.  Ask her to delete manually or something to proceed\n",
    "af_import.main(tag_af, af_fnames)\n",
    "\n",
    "print()\n",
    "for i,fn in enumerate(af_fnames):\n",
    "    print(fn)\n",
    "    p = subprocess.run(['psql', '-c', 'select count(*) from \"af_%s\".af_in_%d;' % (tag_af, i+1)], stdout=subprocess.PIPE)\n",
    "    print(p.stdout.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that raster data covers extent of AF data\n",
    "reload(af_import)\n",
    "dct = {}\n",
    "for i,fn in enumerate(af_fnames):\n",
    "    for tag_rst in (tag_lct, tag_vcf):\n",
    "        cnts = af_import.check_raster_contains_fire(\n",
    "            '\"raster\".\"skel_rst_%s\"' % tag_rst, \n",
    "            '\"af_%s\".\"af_in_%d\"' % (tag_af, i+1)\n",
    "        )\n",
    "        print(os.path.basename(fn), tag_rst, cnts)\n",
    "        dct[(fn,tag_rst)] = cnts\n",
    "\n",
    "if any(_['n_not_contained'] > 0 for _ in  dct.values()):\n",
    "    print('Some fire is not conained in raster')\n",
    "    raise RuntimeError('Some fire is not conained in raster.  Reload raster!!')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process active fire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running \"step 1\" grouping points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(run_step1)\n",
    "run_step1.main(tag_af, firstday=firstday, lastday=lastday, ver='v7m', run_prep = True, run_work=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running \"step 2\" intersection with raster datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(run_step2)\n",
    "\n",
    "assert run_step2.ver == 'v8b'\n",
    "run_step2.main(tag_af, rasters, firstday=firstday, lastday=lastday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default output directory is this diretory (where you have this Jupyter Notebook file), and output file has long name of having tag of each datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '.'\n",
    "shpname = 'out_{0}_{1}_{2}_{3}.shp'.format(tag_af, tag_lct, tag_vcf, tag_regnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'af_' + tag_af\n",
    "tblname = 'out_{0}_{1}_{2}'.format(tag_lct, tag_vcf, tag_regnum)\n",
    "flds = ('v_lct', 'f_lct', 'v_tree', 'v_herb', 'v_bare', 'v_regnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(export_shp)\n",
    "export_shp.main(outdir, schema, tblname, flds, shpname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
