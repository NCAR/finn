{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FINN Preprocessor: Loads Local MODIS raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Envoronments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely no need to be edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import subprocess\n",
    "import shlex\n",
    "from urllib.parse import urlparse\n",
    "from importlib import reload\n",
    "import gdal\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# finn preproc codes\n",
    "sys.path = sys.path + ['../code_anaconda']\n",
    "import downloader\n",
    "import af_import\n",
    "import rst_import\n",
    "import polygon_import\n",
    "import run_step1\n",
    "import run_step2\n",
    "import export_shp\n",
    "import plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database settings\n",
    "os.environ['PGDATABASE'] = 'finn'\n",
    "os.environ['PGUSER'] = 'finn'\n",
    "os.environ['PGPASSWORD'] = 'finn'\n",
    "os.environ['PGHOST'] = 'localhost'\n",
    "os.environ['PGPORT'] = '5432'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the PostGIS database is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info for the database\n",
    "!psql postgres -c 'SELECT version();'\n",
    "!pg_lsclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO i want to move this to Dockerfile somehow\n",
    "# create plpython, needed only once for the database\n",
    "try:\n",
    "    p = subprocess.run(shlex.split(\"psql -d %s -c 'CREATE LANGUAGE plpython3u;'\" % os.environ['PGDATABASE']), \n",
    "                       check=True, stderr=subprocess.PIPE)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    if 'already exists' in e.stderr.decode():\n",
    "        print(e.stderr.decode().replace('ERROR','OK').strip())\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for Land Surface Datasets (land cover, vegetation continuous field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIS land cover types, MODIS vegetation continuous field will be downloaded, if needed, for the region of AF input\n",
    "1. `year_rst`: MODIS raster data year to be used for the analysis\n",
    "2. either  \n",
    "  `four_corners`: (LowerLeft_lon, LowerLeft_Lat, UpperRight_lon, UpperRight_lat) or   \n",
    "  `extent_shp`:  shape file (could be polygon of area of interest, points of fires)\n",
    "\n",
    "Other parameters such as `tag_lct`, `tag_vcf`, `tag_regnum` (identify landcover, vcf and region number dataset) are set automatically for MODIS dataset.  \n",
    "The datasets are imported into database schema \"raster\", with table names \"rst_<i>tag_lct</i>\", or \"rst_modlct_2017\", for example.  \n",
    "An overview raster \"o_32_rst_modlct_2007\" is created as well, as the real dataset is difficult to handle for QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS raster datasets' year\n",
    "year_rst = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic extent of download\n",
    "# specify either one of below (comment out one line with #)\n",
    "\n",
    "four_corners = (-140, 20, 80, 60) # LL corner lon, LL corner LAT, UR corner Lon, UR corner Lat)\n",
    "#extent_shp = './north_central_america.shp'  # shape file of North and Central America (i can create this from AllRegion polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag to identify datasets, automatically set to be modlct_YYYY, modvcf_YYYY\n",
    "tag_lct = 'modlct_%d' % year_rst\n",
    "tag_vcf = 'modvcf_%d' % year_rst\n",
    "\n",
    "# tag for the region number polygon\n",
    "tag_regnum = 'regnum'\n",
    "\n",
    "# definition of variables in the raster files\n",
    "rasters = [\n",
    "        {\n",
    "            'tag': tag_lct,\n",
    "            'kind': 'thematic',\n",
    "            'variable': 'lct'\n",
    "        },\n",
    "        {\n",
    "            'tag': tag_vcf,\n",
    "            'kind': 'continuous',\n",
    "            'variables': ['tree', 'herb', 'bare'],\n",
    "        },\n",
    "        {\n",
    "            'tag': tag_regnum,\n",
    "            'kind': 'polygons',\n",
    "            'variable_in': 'region_num',\n",
    "            'variable': 'regnum',\n",
    "        },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Download raster datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raster files URL and directories to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all downloads are stored in following dir\n",
    "download_rootdir = '../downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthdata's URL for landcover and VCF\n",
    "is_leap = (year_rst % 4 == 0)\n",
    "url_lct = 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/%d.01.01/' % year_rst\n",
    "url_vcf = 'https://e4ftl01.cr.usgs.gov/MOLT/MOD44B.006/%d.03.%02d/' % (year_rst, 5 if is_leap else 6)\n",
    "\n",
    "ddir_lct = download_rootdir +'/'+ ''.join(urlparse(url_lct)[1:3])\n",
    "ddir_vcf = download_rootdir +'/'+ ''.join(urlparse(url_vcf)[1:3])\n",
    "\n",
    "print('LCT downloads goes to %s' % ddir_lct)\n",
    "print('VCF downloads goes to %s' % ddir_vcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download land cover type raster, <b>only for the tiles needed for the active fire file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'four_corners' in locals() and not four_corners is None:\n",
    "    # use four corner\n",
    "    poly = \"POLYGON((%f %f, %f %f, %f %f, %f %f, %f %f))\" % (\n",
    "        four_corners[0], four_corners[1], \n",
    "        four_corners[0], four_corners[3], \n",
    "        four_corners[2], four_corners[3], \n",
    "        four_corners[2], four_corners[1],\n",
    "        four_corners[0], four_corners[1], \n",
    "    )\n",
    "elif 'extent_shp' in locals() and not extent_shp is None:\n",
    "    # use shape file\n",
    "    poly = extent_shp\n",
    "else:\n",
    "    raise RuntimeError('Specify region of interest!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(downloader)\n",
    "downloader.download_only_needed(url = url_lct, droot = download_rootdir, pnts=poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify LCT files' checksum.  If a file is correpted, the file is downloaded again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.purge_corrupted(ddir = ddir_lct, url=url_lct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do similar for vegetation continuous field data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downloader.download_only_needed(url = url_vcf, droot = download_rootdir, pnts=poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.purge_corrupted(ddir_vcf, url=url_vcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import raster datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded files need preprocessing, which is to extract the only raster band needed, and also make coordinate system to be WGS84.  Intermediate files are created in following directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir_lct = '../proc_rst_%s' % tag_lct\n",
    "workdir_vcf = '../proc_rst_%s' % tag_vcf\n",
    "workdir_regnum = '../proc_rst_%s' % tag_regnum\n",
    "\n",
    "print('LCT preprocessing occurs in %s' % workdir_lct)\n",
    "print('VCF preprocessing occurs in %s' % workdir_vcf)\n",
    "print('RegNum preprocessing occurs in %s' % workdir_regnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import land cover type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First grab hdf file names from the download directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string = \"%(ddir_lct)s/MCD12Q1.A%(year_rst)s001.h??v??.006.*.hdf\" % dict(\n",
    "        ddir_lct = ddir_lct, year_rst=year_rst)\n",
    "fnames_lct = sorted(glob.glob(search_string))\n",
    "print('found %d hdf files' % len(fnames_lct) )\n",
    "if len(fnames_lct) == 0:\n",
    "    raise RuntimeError(\"check if downloads are successful and search string to be correct: %s\" % search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command performs three tasks, \"merge\", \"resample\" and \"import\".  First two task creates intermediate GeoTiff files in <i>work_dir</i>.  Last task actually import the data into database's <i>raster</i> schema.\n",
    "\n",
    "You can run only selected tasks with run_XXX flags to `False`, when you know that processing failed in the middle and you resolved the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rst_import)\n",
    "\n",
    "rst_import.main(tag_lct, fnames=fnames_lct, workdir = workdir_lct, run_merge=True, run_resample=True, run_import=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you should able to see the raster in the database using QGIS.  \n",
    "I am also trying to make quick check here creating simple image for QA, but use of GIS tool is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import plotter\n",
    "reload(plotter)\n",
    "try:\n",
    "    plotter.plot('raster.o_32_rst_%s' % tag_lct, '../code_anaconda/modlct.clr')\n",
    "except Exception as e:\n",
    "    print(\"Got this error: \" + str(e))\n",
    "    print(\"Didn't work, use QGIS!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import vegetation continuous fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous steps repeated for vegetation continous fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab hdf file names\n",
    "search_string = \"%(ddir_vcf)s/MOD44B.A%(year)s065.h??v??.006.*.hdf\" % dict(\n",
    "        ddir_vcf = ddir_vcf, year=year_rst)\n",
    "fnames_vcf = sorted(glob.glob(search_string))\n",
    "print('found %d hdf files' % len(fnames_vcf) )\n",
    "if len(fnames_vcf) == 0:\n",
    "    raise RuntimeError(\"check if downloads are successfull and search string to be correct: %s\" % search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rst_import)\n",
    "rst_import.main(tag_vcf, fnames=fnames_vcf, workdir = workdir_vcf, run_merge=True, run_resample=True, run_import=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import plotter\n",
    "reload(plotter)\n",
    "try:\n",
    "    plotter.plot('raster.o_32_rst_%s' % tag_vcf)\n",
    "except Exception as e:\n",
    "    print(\"Got this error: \" + str(e))\n",
    "    print(\"Didn't work, use QGIS!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import countries of the world shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually not a raster but vector data of polygons.  But since it serves conceptually similar function as raster (specify attribute for a given geographic location), I treat it as if it is a raster dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(workdir_regnum, 'All_Countries.shp')):\n",
    "    subprocess.run(['wget', '-P', workdir_regnum, \n",
    "                    'https://s3-us-west-2.amazonaws.com/earthlab-finn/All_Countries.zip'], \n",
    "                   check=True)\n",
    "    subprocess.run(['unzip', os.path.join(workdir_regnum, 'All_Countries.zip'), '-d' , workdir_regnum ], \n",
    "                  check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(polygon_import)\n",
    "polygon_import.main('regnum', shpname = os.path.join(workdir_regnum, 'All_Countries.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
